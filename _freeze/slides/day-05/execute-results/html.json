{
  "hash": "9f79a9af3d00beb382b783986dcfd226",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data\"\nsubtitle: \"Understanding data and information\"\ndate: \"2024-01-31\"\ncategories: [sampling, corpora, tidy-data, data-structures, data-types]\n---\n\n\n## Overview\n\n:::: {.columns}\n::: {.column width=\"60%\"}\nUp for today:\n\n- Understanding data\n- From data to information\n- Documenting the process\n\nLooking ahead:\n\n- Recipe and lab 02\n:::\n\n::: {.column width=\"40%\"}\n![](images/data-information-abstract.png)\n:::\n::::\n\n## Quick reminders\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n{{< fa bell >}} [Course schedule](https://lin-380-s24.github.io/schedule.html)\n\n{{< fa note-sticky >}} [Lessons](https://qtalr.github.io/book/understanding-data.html)\n\n- Intro to Swirl\n- Workspace\n- Vectors\n- Objects\n- Packages and functions\n:::\n\n::: {.column width=\"50%\"}\n{{< fa triangle-exclamation >}} Keeping up with this work is in your best interest.\n\\\n\n{{< fa hand-point-up >}} Don't forget the lessons! They are key to making sure you will be ready for upcoming {{< fa brands r-project >}} programming portions of labs!\n:::\n::::\n\n# Understanding data\nThe raw material of data science\n\n## Populations and samples\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n**Population**\n\nAn idealized set of objects or events that share a common characteristic or belong to a specific category.\n:::\n\n::: {.column width=\"40%\"}\n**Sample**\n\nA finite set of objects or events from drawn from a defined population.\n:::\n::::\n\n![](images/population-sample.drawio.png)\n\n## Sampling\n\n**Sampling frame** Defining the population of interest.\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n**Representativeness**\n\nThe degree to which a sample reflects the characteristics of the population from which it is drawn.\n\n- All samples are biased to some extent.\n- Some samples are more biased than others.\n:::\n\n::: {.column width=\"40%\"}\n*Minimize* bias\n\n- Size\n- Randomization\n- Stratification\n- Balance\n:::\n::::\n\n\n## Corpora\n\n::: {style=\"font-size: 0.8em;\"}\n| Type | Sampling scope | Example |\n|:-----|:----------------| :-------|\n| Reference | General characteristics of a language population | [ANC](https://anc.org/)^[The OANC is a large collection of written and spoken American English from 1990 onwards, with freely available data and annotations.] |\n| Specialized | Specific populations, *e.g.* spoken language, academic writing, *etc.* | [SBCSAE](https://www.linguistics.ucsb.edu/research/santa-barbara-corpus)^[The Santa Barbara Corpus includes transcriptions and audio recordings of natural conversations from across the US.] |\n| Parallel | Directly comparable texts in different languages (*i.e.* translations) | [Europarl](https://www.statmt.org/europarl/)^[The Europarl Parallel Corpus is a collection of proceedings from the European Parliament translated into 21 European languages and aligned at the sentence level to build datasets for statistical machine translation research.] |\n| Comparable | Indirectly comparable texts in different languages or language varieties (*i.e.* similar sampling frames) | [Brown and LOB](https://varieng.helsinki.fi/CoRD/corpora/BROWN/)^[The Brown Corpus is the first computer-readable general corpus of edited American English texts from 1961 containing approximately 1 million words across 500 samples.] |\n:::\n\n::: {.aside}\nVisit [Identifying data and data sources](https://qtalr.github.io/qtalrkit/articles/guide-4.html) for more information on available corpora.\n:::\n\n## Corpus formats\n\n::: {.panel-tabset}\n\n### Unstructured\n\nPlain text\n\n```plain\nThe quick brown fox jumps over the lazy dog.\n```\n\n### Semi-structured\n\nXML\n\n```xml\n<text id = \"1\">\n  <sentence id=\"1\">\n    <word id=\"1\">The</word>\n    <word id=\"2\">quick</word>\n    <word id=\"3\">brown</word>\n    <word id=\"4\">fox</word>\n    <word id=\"5\">jumps</word>\n    <word id=\"6\">over</word>\n    <word id=\"7\">the</word>\n    <word id=\"8\">lazy</word>\n    <word id=\"9\">dog</word>\n    <word id=\"10\">.</word>\n  </sentence>\n</text>\n```\n\n### Structured\n\nR data frame\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n   text_id sentence_id word_id  word\n1        1           1       1   The\n2        1           1       2 quick\n3        1           1       3 brown\n4        1           1       4   fox\n5        1           1       5 jumps\n6        1           1       6  over\n7        1           1       7   the\n8        1           1       8  lazy\n9        1           1       9   dog\n10       1           1      10     .\n```\n\n\n:::\n:::\n\n:::\n\n# From data to information\n\n## Tidy data\n\nPhysical structure\n![](images/ud-tidy.drawio.png)\n\n## Tidy data\n\nSemantic structure\n\n::: {style=\"font-size: 0.8em;\"}\n```xml\n   title             date modality domain          ref_num word       lemma      pos\n   <chr>            <dbl> <fct>    <chr>             <int> <chr>      <chr>      <chr>\n 1 Hotel California  2008 Writing  General Fiction       1 Sound      sound      NNP\n 2 Hotel California  2008 Writing  General Fiction       2 is         be         VBZ\n 3 Hotel California  2008 Writing  General Fiction       3 a          a          DT\n 4 Hotel California  2008 Writing  General Fiction       4 vibration  vibration  NN\n 5 Hotel California  2008 Writing  General Fiction       5 .          .          .\n 6 Hotel California  2008 Writing  General Fiction       6 Sound      sound      NNP\n 7 Hotel California  2008 Writing  General Fiction       7 travels    travel     VBZ\n 8 Hotel California  2008 Writing  General Fiction       8 as         as         IN\n 9 Hotel California  2008 Writing  General Fiction       9 a          a          DT\n10 Hotel California  2008 Writing  General Fiction      10 mechanical mechanical JJ\n```\n:::\n\n- Levels of measurement\n- Unit of observation\n\n## Levels of measurement\n\n```xml\nessay_id part_id sex    group tokens types   ttr prop_l2\nE1       L01     female T2        79    46 0.582   0.987\nE2       L02     female T1        18    18 1       0.667\nE7       L07     male   T3        98    60 0.612   1\nE3       L02     female T3       101    53 0.525   1\nE4       L05     female T1        20    17 0.85    0.9\nE8       L07     male   T4       134    84 0.627   0.978\nE5       L05     female T3       158    80 0.506   0.987\nE6       L05     female T4       184    94 0.511   0.995\n```\n\\\nWhat are the levels of measurement?\n\n::: {style=\"font-size: 0.6em;\"}\n| Level | Description | Question |\n|:------|:------------|:--------|\n| Categorical | Mutually exclusive categories | What? |\n| Ordinal | Ordered categorical | What order? |\n| Numeric | Ordinal intervals | How much/ many? |\n:::\n\n## Unit of observation\n\n```xml\nessay_id part_id sex    group tokens types   ttr prop_l2\nE1       L01     female T2        79    46 0.582   0.987\nE2       L02     female T1        18    18 1       0.667\nE7       L07     male   T3        98    60 0.612   1\nE3       L02     female T3       101    53 0.525   1\nE4       L05     female T1        20    17 0.85    0.9\nE8       L07     male   T4       134    84 0.627   0.978\nE5       L05     female T3       158    80 0.506   0.987\nE6       L05     female T4       184    94 0.511   0.995\n```\n\\\nWhat is the unit of observation?\n\n\n## Transformation\n\nReshaping\n\n![](images/ud-transformations.drawio.png)\n\n## Types: preparation\n\nClean, standardize, and derive key attributes\n\n::: {.panel-tabset}\n\n### Normalization\n\n| Type | Example |\n|:-----|:--------|\n| Case | Lower, UPPER, Title Case |\n| Remove | Punctuation, special characters |\n| Replace | abbreviations, contractions |\n\n### Tokenization{style=\"font-size: 0.8em;\"}\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nAny linguistic unit that can be operationalized.\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  text_id word                 \n    <dbl> <chr>                \n1       1 tokenization enables \n2       1 enables the          \n3       1 the quantitative     \n4       1 quantitative analysis\n5       1 analysis of          \n6       1 of text              \n```\n\n\n:::\n:::\n\n:::\n::::\n\n:::\n\n## Types: enrichment\n\nAugment the dataset with additional information\n\n::: {.panel-tabset}\n\n### Recoding\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n- Decrease levels\n- Increase levels\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 3\n   word       pos   cat        \n   <chr>      <chr> <chr>      \n 1 Recoding   NN    Noun       \n 2 transforms VBZ   Verb       \n 3 values     NNS   Noun       \n 4 to         TO    Preposition\n 5 new        JJ    Adjective  \n 6 values     NNS   Noun       \n 7 more       RBR   Adverb     \n 8 suitable   JJ    Adjective  \n 9 for        IN    Preposition\n10 analysis   NN    Noun       \n```\n\n\n:::\n:::\n\n:::\n::::\n\n### Generation\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 × 6\n   sent_id token_id token    xpos  features                   syntactic_relation\n     <dbl> <chr>    <chr>    <chr> <chr>                      <chr>             \n 1       1 1        Wow      UH    <NA>                       discourse         \n 2       1 2        ,        ,     <NA>                       punct             \n 3       1 3        this     DT    Number=Sing|PronType=Dem   nsubj             \n 4       1 4        is       VBZ   Mood=Ind|Number=Sing|Pers… cop               \n 5       1 5        a        DT    Definite=Ind|PronType=Art  det               \n 6       1 6        great    JJ    Degree=Pos                 amod              \n 7       1 7        tool     NN    Number=Sing                root              \n 8       1 8        for      IN    <NA>                       case              \n 9       1 9        text     NN    Number=Sing                compound          \n10       1 10       analysis NN    Number=Sing                nmod              \n11       1 11       !        .     <NA>                       punct             \n```\n\n\n:::\n:::\n\n\n### Integration\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nConcatenate\n\n![](images/integration-concat-visual.drawio.png)\n:::\n\n::: {.column width=\"50%\"}\nJoin\n\n![](images/integration-join-visual.drawio.png)\n:::\n::::\n\n:::\n\n\n# Documenting the process\n\n## Data origin{.smaller}\n\n+-------------------------+-------------------------------------------------------------+\n| Information             | Description                                                 |\n+=========================+=============================================================+\n| Resource name           | Name of the corpus resource.                                |\n+-------------------------+-------------------------------------------------------------+\n| Data source             | URL, DOI, *etc.*                                            |\n+-------------------------+-------------------------------------------------------------+\n| Data sampling frame     | Language, language variety, modality, genre, *etc.*         |\n+-------------------------+-------------------------------------------------------------+\n| Data collection date(s) | The date or date range of the data collection.              |\n+-------------------------+-------------------------------------------------------------+\n| Data format             | Plain text, XML, HTML, *etc.*                               |\n+-------------------------+-------------------------------------------------------------+\n| Data schema             | Relationships between data elements: files, folders, *etc.* |\n+-------------------------+-------------------------------------------------------------+\n| License                 | CC BY, CC BY-NC, *etc.*                                     |\n+-------------------------+-------------------------------------------------------------+\n| Attribution             | Citation information for the data source.                   |\n+-------------------------+-------------------------------------------------------------+\n\n: Data origin template {#tbl-do tbl-colwidths=\"[35, 65]\"}\n\n## Data dictionary{.smaller}\n\n+------------------------+--------------------------------------------------------------------------------------------------------------+\n| Information            | Description                                                                                                  |\n+========================+==============================================================================================================+\n| Variable name          | The name of the variable as it appears in the dataset, *e.g.* `participant_id`, `modality`, *etc.*           |\n+------------------------+--------------------------------------------------------------------------------------------------------------+\n| Readable variable name | A human-readable name for the variable, *e.g.* 'Participant ID', 'Language modality', *etc.*                 |\n+------------------------+--------------------------------------------------------------------------------------------------------------+\n| Variable type          | The type of information that the variable contains, *e.g.* 'categorical', 'ordinal', *etc.*                  |\n+------------------------+--------------------------------------------------------------------------------------------------------------+\n| Variable description   | A prose description expanding on the readable name and can include measurement units, allowed values, *etc.* |\n+------------------------+--------------------------------------------------------------------------------------------------------------+\n\n: Data dictionary template {#tbl-dd tbl-colwidths=\"[35, 65]\"}\n\n# Looking ahead\n\n## Recipe and lab\n\n- Recipe 02: [Reading, inspecting, and writing datasets](https://qtalr.github.io/qtalrkit/articles/recipe-2.html)\n- Lab 02: [Dive into datasets](https://github.com/qtalr/lab-02)\n\n\n<!--\nKey points to address:\n\n- Data literacy:\n  - How populations, samples, and corpora align with research questions\n  - Nuances between data and information\n- Research skills:\n  - Understand the process of organizing and transforming data\n  - Importance of documenting data for design and implementation of research\n- Programming skills:\n  - Making connections with R-specific resources and tools (Lessons and Recipes)\n-->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}